---
title: "Using the OpenAI Client"
description: "Example overview page before API endpoints"
---

<Info>
  A complete rewrite of the library recently took place, a lot of things have
  changed. Developers recommend immediate update. For more information access:
  [Migration Guide](https://github.com/openai/openai-python/discussions/742)
</Info>
This example shows how to use the Openai client with LlamaAPI

<CodeGroup>
```python Python - New
# This example is the new way to use the OpenAI lib for python
from openai import OpenAI

client = OpenAI(
api_key = "<your_openai_api_key>",
base_url = "https://api.llama-api.com"
)

    response = client.chat.completions.create(
    model="llama-13b-chat",
    messages=[
        {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
        {"role": "user", "content": "Who were the founders of Microsoft?"}
    ]

)

#print(response)
print(response.model_dump_json(indent=2))
print(response.choices[0].message.content)

````
```python Python - Old
# This example is the old way to use the OpenAI lib for python

import json
from llamaapi import LlamaAPI

llama = LlamaAPI("<your_openai_api_key>")

api_request_json = {
    "messages": [{"role": "user", "content": "What is the weather like in Boston?"},],
    "functions": [
        {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "days": {
                        "type": "number",
                        "description": "for how many days ahead you wants the forecast",
                    },
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                },
            },
            "required": ["location", "days"],
        }
    ],
    "stream": False,
    "function_call": "get_current_weather",
}

# Make your request and handle the response
response = llama.run(api_request_json)
print(json.dumps(response.json(), indent=2))
````

</CodeGroup>
